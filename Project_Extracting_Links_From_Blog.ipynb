{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "\n",
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=0.3,  # <-- Super slow! We can only make a request once every 10 seconds!!\n",
    "    check_every_n_seconds=0.1,  # Wake up every 100 ms to check whether allowed to make a request,\n",
    "    max_bucket_size=10,  # Controls the maximum burst size.\n",
    ")\n",
    "\n",
    "api_key = os.environ.get(\"MISTRAL_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"MISTRAL_API_KEY is not set or could not be loaded!\")\n",
    "\n",
    "model = ChatMistralAI(model=\"mistral-large-latest\", api_key=api_key, rate_limiter=rate_limiter)\n",
    "\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "documents = loader.load()\n",
    "\n",
    "doc = documents[0]\n",
    "#page_content = doc.page_content\n",
    "#page_content = doc.page_content[:10000]\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_overlap=0)\n",
    "splits = text_splitter.split_text(doc.page_content)\n",
    "\n",
    "def flatten(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list\n",
    "\n",
    "#Each chunk is into text format but chain takes dict so we have turn each chunk into dict.\n",
    "#Each split converted to a list of dict.\n",
    "\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "prep = RunnableLambda(\n",
    "    lambda x: [{\"input\": doc} for doc in text_splitter.split_text(x)]\n",
    ")\n",
    "\n",
    "\n",
    "from typing import Optional\n",
    "class Paper(BaseModel):\n",
    "    \"\"\"Information about papers mentioned.\"\"\"\n",
    "    title: str\n",
    "    author: Optional[str]\n",
    "\n",
    "\n",
    "class Info(BaseModel):\n",
    "    \"\"\"Information to extract\"\"\"\n",
    "    papers: List[Paper]\n",
    "\n",
    "paper_extraction_function = [\n",
    "    convert_pydantic_to_openai_function(Info)\n",
    "]\n",
    "\n",
    "extraction_model = model.bind_tools(\n",
    "    tools=paper_extraction_function, \n",
    ")\n",
    "\n",
    "template = \"\"\"A article will be passed to you. Extract from it all papers that are mentioned by this article. \n",
    "\n",
    "Do not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an empty list.\n",
    "\n",
    "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prep | extraction_chain.map() | flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_response = chain.invoke(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ai_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers = []\n",
    "\n",
    "# Iterate through each response in ai_response\n",
    "for output_tuple in ai_response:\n",
    "    # Extract the actual dictionary from the tuple (assuming the dictionary is the first element in the tuple)\n",
    "    output = output_tuple[1]  # Use [1] to get the dictionary part of the tuple\n",
    "\n",
    "    # Check if output is not None and if there are tool calls in the response\n",
    "    if output and 'tool_calls' in output:\n",
    "        for tool_call in output['tool_calls']:\n",
    "            # Extract the papers from the 'Info' function arguments\n",
    "            papers = json.loads(tool_call['function']['arguments']).get('papers', [])\n",
    "            # Add papers to the all_papers list\n",
    "            all_papers.extend(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"title\": \"Chain of thought\",\n",
      "    \"author\": \"Wei et al\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Tree of Thoughts\",\n",
      "    \"author\": \"Yao et al\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"LLM+P\",\n",
      "    \"author\": \"Liu et al\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"ReAct\",\n",
      "    \"author\": \"Yao et al\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Reflexion\",\n",
      "    \"author\": \"Shinn & Labash\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Chain of Hindsight\",\n",
      "    \"author\": \"Liu et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Algorithm Distillation\",\n",
      "    \"author\": \"Laskin et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Laskin et al. 2023\",\n",
      "    \"author\": null\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Duan et al. 2017\",\n",
      "    \"author\": null\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Miller 1956\",\n",
      "    \"author\": null\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"MRKL\",\n",
      "    \"author\": \"Karpas et al. 2022\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"TALM\",\n",
      "    \"author\": \"Parisi et al. 2022\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Toolformer\",\n",
      "    \"author\": \"Schick et al. 2023\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"HuggingGPT\",\n",
      "    \"author\": \"Shen et al. 2023\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"API-Bank\",\n",
      "    \"author\": \"Li et al. 2023\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"ChemCrow\",\n",
      "    \"author\": \"Bran et al. 2023\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Generative Agents\",\n",
      "    \"author\": \"Park, et al. 2023\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Park et al. 2023\",\n",
      "    \"author\": \"Park, et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Chain of thought prompting elicits reasoning in large language models.\",\n",
      "    \"author\": \"Wei et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Tree of Thoughts: Dliberate Problem Solving with Large Language Models.\",\n",
      "    \"author\": \"Yao et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Chain of Hindsight Aligns Language Models with Feedback\",\n",
      "    \"author\": \"Liu et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"LLM+P: Empowering Large Language Models with Optimal Planning Proficiency\",\n",
      "    \"author\": \"Liu et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"ReAct: Synergizing reasoning and acting in language models.\",\n",
      "    \"author\": \"Yao et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Reflexion: an autonomous agent with dynamic memory and self-reflection\",\n",
      "    \"author\": \"Shinn & Labash\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"In-context Reinforcement Learning with Algorithm Distillation\",\n",
      "    \"author\": \"Laskin et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.\",\n",
      "    \"author\": \"Karpas et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Webgpt: Browser-assisted question-answering with human feedback.\",\n",
      "    \"author\": \"Nakano et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"TALM: Tool Augmented Language Models\",\n",
      "    \"author\": \"Parisi et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Toolformer: Language Models Can Teach Themselves to Use Tools.\",\n",
      "    \"author\": \"Schick et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"API-Bank: A Benchmark for Tool-Augmented LLMs\",\n",
      "    \"author\": \"Li et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace\",\n",
      "    \"author\": \"Shen et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"ChemCrow: Augmenting large-language models with chemistry tools.\",\n",
      "    \"author\": \"Bran et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Emergent autonomous scientific research capabilities of large language models.\",\n",
      "    \"author\": \"Boiko et al.\"\n",
      "  },\n",
      "  {\n",
      "    \"title\": \"Generative Agents: Interactive Simulacra of Human Behavior.\",\n",
      "    \"author\": \"Joon Sung Park, et al.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Optional: Remove duplicate papers based on title\n",
    "unique_papers = []\n",
    "seen_titles = set()\n",
    "\n",
    "for paper in all_papers:\n",
    "    title = paper.get('title')\n",
    "    if title not in seen_titles:\n",
    "        unique_papers.append(paper)\n",
    "        seen_titles.add(title)\n",
    "\n",
    "# Print the unique papers\n",
    "print(json.dumps(unique_papers, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Instead of Parsing, we can try model itself to extract the information from \"ai_response\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
